{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section3_8_9.ipynb",
      "provenance": [],
      "mount_file_id": "19HC4rEL3R-utZL5UUjaVp1Po0y48bazu",
      "authorship_tag": "ABX9TyOjmJKWdUspGMv1/r/SP+vC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DU-ds/pyspark_udemy/blob/main/Section3_8_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoWBQQcZuWbf",
        "outputId": "f4713c71-3c39-45fe-c527-f88ba85bf131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\u001b[0m\r                                                                               \rHit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\u001b[0m\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (103 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "58 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "original.csv  spark-2.3.1-bin-hadoop2.7      spark-2.3.1-bin-hadoop2.7.tgz.1\n",
            "sample_data   spark-2.3.1-bin-hadoop2.7.tgz  spark-warehouse\n",
            "+---+----------+----------+------+---------------+--------------------+---------+----------+----------+\n",
            "| id|first_name| last_name|gender|           City|            JobTitle|   Salary|  Latitude| Longitude|\n",
            "+---+----------+----------+------+---------------+--------------------+---------+----------+----------+\n",
            "|  1|   Melinde| Shilburne|Female|      Nowa Ruda| Assistant Professor|$57438.18| 50.577408| 16.496717|\n",
            "|  2|  Kimberly|Von Welden|Female|         Bulgan|       Programmer II|$62846.60|  48.82316| 103.52182|\n",
            "|  3|    Alvera|  Di Boldi|Female|           null|                null|$57576.52| 39.994747|116.339775|\n",
            "|  4|   Shannon| O'Griffin|  Male|  Divnomorskoye|Budget/Accounting...|$61489.23| 44.504723| 38.130016|\n",
            "|  5|  Sherwood|   Macieja|  Male|      Mytishchi|            VP Sales|$63863.09|      null| 37.648994|\n",
            "|  6|     Maris|      Folk|Female|Kinsealy-Drinan|      Civil Engineer|$30101.16| 53.426613|-6.1644998|\n",
            "|  7|     Masha|    Divers|Female|         Dachun|                null|$25090.87| 24.879416|118.930115|\n",
            "|  8|   Goddart|     Flear|  Male|      Trélissac|Desktop Support T...|$46116.36| 45.190517| 0.7423124|\n",
            "|  9|      Roth|O'Cannavan|  Male|         Heitan|VP Product Manage...|$73697.10| 32.027935| 106.65711|\n",
            "| 10|      Bran|   Trahear|  Male|       Arbeláez|Mechanical System...|$68098.42|  4.272793|-74.416016|\n",
            "| 11|    Kylynn|   Lockart|Female|       El Cardo|Nuclear Power Eng...|$13604.63|     -5.85| -79.88333|\n",
            "| 12|       Rey|    Meharg|Female|    Wangqingtuo|Systems Administr...|$73423.70|  39.17238| 116.93161|\n",
            "| 13|      Kerr|    Braden|  Male|      Sułkowice|Compensation Analyst|$33432.99|  49.81518| 19.377174|\n",
            "| 14|    Mickie| Whanstall|  Male|    Springfield|Assistant Media P...|$50838.53|  42.10148|-72.576675|\n",
            "| 15|    Kaspar|     Pally|  Male|         Chrást|  Analyst Programmer|$40163.03|  49.79233| 13.491532|\n",
            "| 16|    Norbie|    Gwyllt|  Male|         Xijiao|              Editor|$32492.73| 43.494576|  5.897802|\n",
            "| 17|    Claude|    Briant|Female|      Mieścisko|Research Assistan...|$51862.48| 52.744167| 17.327864|\n",
            "| 18|     Thain|    Habbon|  Male| Foros do Trapo|     Design Engineer|$42135.67| 38.696247| -8.709834|\n",
            "| 19|  Tiffanie|  Pattison|Female|    Jabungsisir|Senior Financial ...|$91925.08|-7.7232566| 113.46868|\n",
            "| 20|    Ettore|  Gerriets|  Male|          Pedra| Staff Accountant IV|$73921.33| 40.717205|-8.3625145|\n",
            "+---+----------+----------+------+---------------+--------------------+---------+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! apt update\n",
        "! apt install openjdk-8-jdk-headless -qq > /dev/null\n",
        "! wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "! tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "! pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\"\n",
        "\n",
        "! ls\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark\n",
        "\n",
        "from pyspark.sql import types\n",
        "schema = types.StructType([\n",
        "                           types.StructField('id', types.IntegerType()),\n",
        "                           types.StructField(\"first_name\", types.StringType()),\n",
        "                           types.StructField(\"last_name\", types.StringType()),\n",
        "                           types.StructField(\"gender\", types.StringType()),\n",
        "                           types.StructField(\"City\", types.StringType()),\n",
        "                           types.StructField(\"JobTitle\", types.StringType()),\n",
        "                           types.StructField(\"Salary\", types.StringType()),\n",
        "                           types.StructField(\"Latitude\", types.FloatType()),\n",
        "                           types.StructField(\"Longitude\", types.FloatType())\n",
        "])\n",
        "\n",
        "df = spark.read.csv(\"original.csv\", header=True, schema=schema)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"clean_salary\", df.Salary.substr(2, 100).cast(\"float\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdUSX-_Jusjq",
        "outputId": "c3b22388-d79b-455c-c775-9c6d42aaa47e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+----------+------+---------------+--------------------+---------+----------+----------+------------+\n",
            "| id|first_name| last_name|gender|           City|            JobTitle|   Salary|  Latitude| Longitude|clean_salary|\n",
            "+---+----------+----------+------+---------------+--------------------+---------+----------+----------+------------+\n",
            "|  1|   Melinde| Shilburne|Female|      Nowa Ruda| Assistant Professor|$57438.18| 50.577408| 16.496717|    57438.18|\n",
            "|  2|  Kimberly|Von Welden|Female|         Bulgan|       Programmer II|$62846.60|  48.82316| 103.52182|     62846.6|\n",
            "|  3|    Alvera|  Di Boldi|Female|           null|                null|$57576.52| 39.994747|116.339775|    57576.52|\n",
            "|  4|   Shannon| O'Griffin|  Male|  Divnomorskoye|Budget/Accounting...|$61489.23| 44.504723| 38.130016|    61489.23|\n",
            "|  5|  Sherwood|   Macieja|  Male|      Mytishchi|            VP Sales|$63863.09|      null| 37.648994|    63863.09|\n",
            "|  6|     Maris|      Folk|Female|Kinsealy-Drinan|      Civil Engineer|$30101.16| 53.426613|-6.1644998|    30101.16|\n",
            "|  7|     Masha|    Divers|Female|         Dachun|                null|$25090.87| 24.879416|118.930115|    25090.87|\n",
            "|  8|   Goddart|     Flear|  Male|      Trélissac|Desktop Support T...|$46116.36| 45.190517| 0.7423124|    46116.36|\n",
            "|  9|      Roth|O'Cannavan|  Male|         Heitan|VP Product Manage...|$73697.10| 32.027935| 106.65711|     73697.1|\n",
            "| 10|      Bran|   Trahear|  Male|       Arbeláez|Mechanical System...|$68098.42|  4.272793|-74.416016|    68098.42|\n",
            "| 11|    Kylynn|   Lockart|Female|       El Cardo|Nuclear Power Eng...|$13604.63|     -5.85| -79.88333|    13604.63|\n",
            "| 12|       Rey|    Meharg|Female|    Wangqingtuo|Systems Administr...|$73423.70|  39.17238| 116.93161|     73423.7|\n",
            "| 13|      Kerr|    Braden|  Male|      Sułkowice|Compensation Analyst|$33432.99|  49.81518| 19.377174|    33432.99|\n",
            "| 14|    Mickie| Whanstall|  Male|    Springfield|Assistant Media P...|$50838.53|  42.10148|-72.576675|    50838.53|\n",
            "| 15|    Kaspar|     Pally|  Male|         Chrást|  Analyst Programmer|$40163.03|  49.79233| 13.491532|    40163.03|\n",
            "| 16|    Norbie|    Gwyllt|  Male|         Xijiao|              Editor|$32492.73| 43.494576|  5.897802|    32492.73|\n",
            "| 17|    Claude|    Briant|Female|      Mieścisko|Research Assistan...|$51862.48| 52.744167| 17.327864|    51862.48|\n",
            "| 18|     Thain|    Habbon|  Male| Foros do Trapo|     Design Engineer|$42135.67| 38.696247| -8.709834|    42135.67|\n",
            "| 19|  Tiffanie|  Pattison|Female|    Jabungsisir|Senior Financial ...|$91925.08|-7.7232566| 113.46868|    91925.08|\n",
            "| 20|    Ettore|  Gerriets|  Male|          Pedra| Staff Accountant IV|$73921.33| 40.717205|-8.3625145|    73921.33|\n",
            "+---+----------+----------+------+---------------+--------------------+---------+----------+----------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"gender\").agg(sqlf.sum('clean_salary').alias(\"total\"),\n",
        "                         sqlf.avg(\"clean_salary\").alias(\"average\"),\n",
        "                         sqlf.min(\"clean_salary\").alias(\"min\"),\n",
        "                         sqlf.max(\"clean_salary\").alias(\"max\")\n",
        "                         ).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxpD-awjvXef",
        "outputId": "2ecdc4eb-f841-4ef8-9aff-8b354678907f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+-----------------+--------+--------+\n",
            "|gender|               total|          average|     min|     max|\n",
            "+------+--------------------+-----------------+--------+--------+\n",
            "|Female|2.7364519950195312E7|55618.94298820185|10616.44|99948.28|\n",
            "|  Male|2.8123435678710938E7|55361.09385573019|10101.92|99942.92|\n",
            "+------+--------------------+-----------------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.groupBy(\"gender\", \"city\").agg(sqlf.sum('clean_salary').alias(\"total\"),\n",
        "                         sqlf.avg(\"clean_salary\").alias(\"average\"),\n",
        "                         sqlf.min(\"clean_salary\").alias(\"min\"),\n",
        "                         sqlf.max(\"clean_salary\").alias(\"max\")\n",
        "                         ).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl6ps2U0wY5I",
        "outputId": "4ddf0049-ebe6-427b-e36d-b7170f6754a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------+----------------+----------------+--------+--------+\n",
            "|gender|             city|           total|         average|     min|     max|\n",
            "+------+-----------------+----------------+----------------+--------+--------+\n",
            "|Female|           Dachun| 25090.869140625| 25090.869140625|25090.87|25090.87|\n",
            "|Female|      Trollhättan|106623.369140625|53311.6845703125|26830.47| 79792.9|\n",
            "|  Male|          Wenshao| 18941.509765625| 18941.509765625|18941.51|18941.51|\n",
            "|Female|            Lanas| 13765.900390625| 13765.900390625| 13765.9| 13765.9|\n",
            "|  Male|            Mörön|    77940.078125|    77940.078125|77940.08|77940.08|\n",
            "|Female|             Same|   73369.7265625|   73369.7265625|73369.73|73369.73|\n",
            "|Female|          Sawahan|  24608.83984375|  24608.83984375|24608.84|24608.84|\n",
            "|  Male|Monte da Boavista|     98586.71875|     98586.71875|98586.72|98586.72|\n",
            "|Female|         Nusajaya|    71637.921875|    71637.921875|71637.92|71637.92|\n",
            "|Female|            Kista|   96192.3984375|   96192.3984375| 96192.4| 96192.4|\n",
            "|  Male|       Pittsburgh|    83121.890625|    83121.890625|83121.89|83121.89|\n",
            "|  Male|       Neftegorsk|     97531.46875|     97531.46875|97531.47|97531.47|\n",
            "|Female|          Yanaoca|     54906.21875|     54906.21875|54906.22|54906.22|\n",
            "|  Male|            Tambo|  40264.91015625|  40264.91015625|40264.91|40264.91|\n",
            "|  Male|        Mytishchi|  63863.08984375|  63863.08984375|63863.09|63863.09|\n",
            "|  Male|            Pedra|    73921.328125|    73921.328125|73921.33|73921.33|\n",
            "|Female|            Dhaka|    68368.546875|    68368.546875|68368.55|68368.55|\n",
            "|  Male|        Mosteiros|  62508.87109375|  62508.87109375|62508.87|62508.87|\n",
            "|  Male|           Roanne|   93339.9921875|   93339.9921875|93339.99|93339.99|\n",
            "|Female|        Eindhoven| 24042.099609375| 24042.099609375| 24042.1| 24042.1|\n",
            "+------+-----------------+----------------+----------------+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [\"gender\", \"city\", \"JobTitle\"]\n",
        "df1 = df.groupBy(*lst).agg(sqlf.sum('clean_salary').alias(\"total\"),\n",
        "                         sqlf.avg(\"clean_salary\").alias(\"average\"),\n",
        "                         sqlf.min(\"clean_salary\").alias(\"min\"),\n",
        "                         sqlf.max(\"clean_salary\").alias(\"max\")\n",
        "                         )\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFujXg_4wZlF",
        "outputId": "872b0e7b-c24c-4dd3-92a7-427abb7665b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+--------------------+----------------+----------------+--------+--------+\n",
            "|gender|                city|            JobTitle|           total|         average|     min|     max|\n",
            "+------+--------------------+--------------------+----------------+----------------+--------+--------+\n",
            "|  Male|              Xijiao|         Developer I|13708.0302734375|13708.0302734375|13708.03|13708.03|\n",
            "|Female|             Macarse|  Help Desk Operator|   68709.0234375|   68709.0234375|68709.02|68709.02|\n",
            "|Female|          El Salitre|Systems Administr...|    94859.078125|    94859.078125|94859.08|94859.08|\n",
            "|  Male|Santo Antônio do ...|        Food Chemist|        17283.25|        17283.25|17283.25|17283.25|\n",
            "|  Male|                Bile|               Nurse|   97909.8828125|   97909.8828125|97909.88|97909.88|\n",
            "|Female|            Welisara|     Legal Assistant|    48376.421875|    48376.421875|48376.42|48376.42|\n",
            "|Female|              Dachun|                null| 25090.869140625| 25090.869140625|25090.87|25090.87|\n",
            "|  Male|               Rosso|Physical Therapy ...|  36879.44140625|  36879.44140625|36879.44|36879.44|\n",
            "|Female|               Sanli|   Marketing Manager|      73174.1875|      73174.1875|73174.19|73174.19|\n",
            "|  Male|        Niños Heroes|Human Resources A...|  41345.69140625|  41345.69140625|41345.69|41345.69|\n",
            "|Female|              Tromsø| Geological Engineer|   43382.6015625|   43382.6015625| 43382.6| 43382.6|\n",
            "|  Male|         Spas-Zaulok|Human Resources M...|    41604.671875|    41604.671875|41604.67|41604.67|\n",
            "|Female|               Vigia| Executive Secretary|  60274.01953125|  60274.01953125|60274.02|60274.02|\n",
            "|  Male|           Huangyang|Analog Circuit De...|  63001.94921875|  63001.94921875|63001.95|63001.95|\n",
            "|  Male|             Puyehue|    Product Engineer|   51163.6796875|   51163.6796875|51163.68|51163.68|\n",
            "|Female|           Mesopotam|Environmental Spe...|     99948.28125|     99948.28125|99948.28|99948.28|\n",
            "|Female|          Karabanovo|  Nurse Practicioner|    45568.921875|    45568.921875|45568.92|45568.92|\n",
            "|  Male|          Bilohirs’k|  Help Desk Operator|  51271.98828125|  51271.98828125|51271.99|51271.99|\n",
            "|  Male|             Dobrica| Assistant Professor|    59318.890625|    59318.890625|59318.89|59318.89|\n",
            "|  Male|           Sawahbaru|  Research Associate|   99013.7109375|   99013.7109375|99013.71|99013.71|\n",
            "+------+--------------------+--------------------+----------------+----------------+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.write.csv(\"df1.csv\")\n",
        "df1.write.json(\"df1.json\")\n",
        "df1.write.parquet(\"df1.parquet\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pxb-Y49wwZ5q",
        "outputId": "154c483f-54e9-4a20-967a-bcf1d7c5f2a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o483.csv.\n: org.apache.spark.sql.AnalysisException: path file:/content/df1.csv already exists.;\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:109)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:225)\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:642)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-01335f0881b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df1.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df1.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping)\u001b[0m\n\u001b[1;32m    883\u001b[0m                        \u001b[0mignoreTrailingWhiteSpace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignoreTrailingWhiteSpace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                        charToEscapeQuoteEscaping=charToEscapeQuoteEscaping)\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: 'path file:/content/df1.csv already exists.;'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"df1.csv\")\n",
        "files.download(\"df1.parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "IcgMax_JwaP7",
        "outputId": "611aff2c-7e18-4dd2-c02e-34ea7f170f51"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9c5a5794-50b9-4f0a-b432-232edbddab68\", \"df1.csv\", 40960)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_75f51e89-02b7-4524-9654-835b0930b069\", \"df1.parquet\", 53248)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -r \"df1.csv\" \"/content/drive/My Drive/\"\n",
        "! cp -r \"df1.parquet\" \"/content/drive/My Drive/\""
      ],
      "metadata": {
        "id": "9y0wG89PwajU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EiUwmILFwa9P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}